{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyiMu4piedDj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: Explain the differences between AI, ML, Deep Learning (DL), and Data\n",
        "Science (DS).\n",
        "\n",
        "Answer: AI(Artificial Intelligence)-AI is the broad field of computer that aims to mimicking human intelligence. Ex- self driving cars, recommendation system.\n",
        "\n",
        "ML(Machine Learning)-it is a subset of AI that uses algorithm to learn pattern from data and increase performance. Ex- Email spam detection.\n",
        "\n",
        "DL(Deep learning)- it is a subset of ML that use netural network with multiple layer to process complex data such as image or videos. Ex- face recognization on smartphone.\n",
        "\n",
        "DS(Data science)- it is a field that combines statistic,mathematic,programming and domain knowledge.\n",
        "\n",
        "\n",
        "Question 2: What are the types of machine learning? Describe each with one\n",
        "real-world example.\n",
        "\n",
        "Answer: the types of machine learning is supervised learning, unsupervised learning , semisupervised learning and reinforcement learning.\n",
        "\n",
        "Supervised learning- model learns from labelled data i.e input output pairs ex- predicting house prices based on area ,location and no. of rooms.\n",
        "\n",
        "Unsupervised learning- model finds hidden patterns in unlabeled data. There are no target value or historical data . ex- customer segmentation.\n",
        "\n",
        "Semisupervised learning- it is combination of supervised and unsupervised learning ,here some data will be labelled and some will be unlabelled data. ex-in Netflix all customer are grouped into region and based on customer preference they will get suggestion .\n",
        "\n",
        "Reinforcement learning- model learns by interacting with an environment and receive reward. ex- training robot to walk.\n",
        "\n",
        "Question 3: Define overfitting, underfitting, and the bias-variance trade off in machine\n",
        "learning.\n",
        "\n",
        "Answer: Overfitting: When a model learns the training data too well including noise, leading to poor performance on new/unseen data.\n",
        "\n",
        "Underfitting: When a model is too simple to capture the underlying pattern in data, leading to poor performance on both training and test data.\n",
        "\n",
        "Bias-Variance Trade off: Balancing between bias (error due to overly simplistic models) and variance (error due to overly complex models). The goal is to find the right model complexity that generalizes well.\n",
        "\n",
        "\n",
        "Question 4: What are outliers in a dataset, and list three common techniques for\n",
        "handling them.\n",
        "\n",
        "Answer: Outliers: Data points that are significantly different from the majority of the data. They can distort statistical results and reduce model performance.\n",
        "Techniques to handle outliers are-\n",
        "\n",
        "1.dropping the outliers- remove the datapoints that fall outside the acceptable range, it is good when data set is large and losing a few value doesnot affect results and it is used when you want to clean data.\n",
        "\n",
        "\n",
        "2. Capping the outliear-  Replacing extreme values with nearest acceptable values , it keep data size same but limit their effect and it used when you want to keep values but limit their effect.\n",
        "\n",
        "\n",
        "\n",
        "3. replace with mean and median\n",
        "\n",
        "\n",
        "Question 5: Explain the process of handling missing values and mention one\n",
        "imputation technique for numerical and one for categorical data.\n",
        "\n",
        "Answer- Process of handling missing values:\n",
        "\n",
        "1. Identify missing values.\n",
        "\n",
        "\n",
        "2. Analyze the reason (random or systematic).\n",
        "\n",
        "\n",
        "3. Decide whether to remove or impute.\n",
        "\n",
        "\n",
        "\n",
        "For numerical data: Use mean or median imputation (replace missing values with mean/median of the column).\n",
        "Example: If some students’ marks are missing, replace them with the median marks.\n",
        "\n",
        "For categorical data: Use mode imputation (replace missing values with the most frequent category).\n",
        "Example: If gender data is missing, replace with the most common category (Male/Female).\n",
        "\n"
      ],
      "metadata": {
        "id": "jFuDR0JJekAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6: Write a Python program that:\n",
        "#● Creates a synthetic imbalanced dataset with make_classification() from\n",
        "#sklearn.datasets.\n",
        "#● Prints the class distribution.\n",
        "#(Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "5Xla1gnoe_FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=5, n_classes=2,\n",
        "                           weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "distribution = dict(zip(unique, counts))\n",
        "print(\"Class distribution:\", distribution)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r83FW07je_Iw",
        "outputId": "79649e1d-1b12-4d6e-de14-cecf76ec6025"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: {np.int64(0): np.int64(895), np.int64(1): np.int64(105)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Implement one-hot encoding using pandas for the following list of colors:\n",
        "#['Red', 'Green', 'Blue', 'Green', 'Red']. Print the resulting dataframe.\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n"
      ],
      "metadata": {
        "id": "IDvwsNVgfA3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "colors = ['Red', 'Green', 'Blue', 'Green', 'Red']\n",
        "\n",
        "df = pd.DataFrame(colors, columns=['Color'])\n",
        "\n",
        "encoded_df = pd.get_dummies(df, columns=['Color'])\n",
        "\n",
        "print(encoded_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDtaviAgfBGW",
        "outputId": "fb66f4f7-3255-4b57-c903-2710e736b5f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0       False        False       True\n",
            "1       False         True      False\n",
            "2        True        False      False\n",
            "3       False         True      False\n",
            "4       False        False       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Implement Min-Max scaling on the following list of numbers [2, 5, 10, 15,\n",
        "#20] using sklearn.preprocessing.MinMaxScaler. Print the scaled array.\n",
        "#(Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "131QbCSBfBbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[2], [5], [10], [15], [20]])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Scaled Data:\\n\", scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mfZrK2efBmk",
        "outputId": "c6e91bbe-0ed1-40ae-8e25-289c05260b83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Data:\n",
            " [[0.        ]\n",
            " [0.16666667]\n",
            " [0.44444444]\n",
            " [0.72222222]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jw5UJyykfCLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wI9Ew4nfCWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}